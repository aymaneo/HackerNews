# Hacker News 

## Quick Start

### Option 1: One Command (Easiest!)
```bash
./run_pipeline.sh
```
This will install dependencies, start Kafka, fetch data, and run both Bronze and Silver layers.

### Option 2: Step by Step
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Start Kafka
docker-compose up -d
sleep 15

# 3. Fetch data from HN API â†’ Kafka
python3 utils/kafka_producer.py --mode top

# 4. Load Kafka â†’ Bronze Delta Lake
python3 run_spark_bronze.py

# 5. Clean Bronze â†’ Silver Delta Lake
python3 run_spark_silver.py
```


---



### Kafka UI
Open in browser: **http://localhost:8082**
- View topics: `hn-stories`, `hn-comments`

### Query Delta Lake (Jupyter Notebook)
```bash
jupyter notebook explore_data.ipynb
```

---

## ğŸ—ï¸ Architecture

```
HN API â†’ Kafka Producer â†’ Kafka Topics
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  BRONZE Layer  â”‚  â† Spark + Delta Lake
                    â”‚  (Raw Data)    â”‚     â€¢ Kafka â†’ Delta
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ ACID writes
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  SILVER Layer  â”‚  â† Spark + Delta Lake
                    â”‚  (Clean Data)  â”‚     â€¢ HTML cleaning
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Quality scoring
```

---

## ğŸ“ Project Structure

```
hackernews/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py              # Configuration
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ hn_api_client.py       # HN API client
â”‚   â””â”€â”€ kafka_producer.py      # Producer (API â†’ Kafka)
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ spark_loader.py        # Bronze (Kafka â†’ Delta) 
â”œâ”€â”€ silver/
â”‚   â””â”€â”€ spark_processor.py     # Silver (Bronze â†’ Silver) 
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                # Bronze Delta tables
â”‚   â”‚   â”œâ”€â”€ stories/
â”‚   â”‚   â””â”€â”€ comments/
â”‚   â””â”€â”€ silver/                # Silver Delta tables
â”‚       â”œâ”€â”€ stories/
â”‚       â””â”€â”€ comments/
â”œâ”€â”€ docker-compose.yml         # Kafka infrastructure
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_pipeline.sh            # One-command launcher
â”œâ”€â”€ run_spark_bronze.py        # Run Bronze layer
â”œâ”€â”€ run_spark_silver.py        # Run Silver layer
â”œâ”€â”€ test_delta.py              # Test Delta Lake
â””â”€â”€ explore_data.ipynb         # Query data (Jupyter)
```

---

## Data Schema

### Bronze Layer (Raw from Kafka)
**Stories**: id, by, title, url, score, descendants, time, type, text, kids, _kafka_offset, _kafka_partition, _bronze_ingested_at

**Comments**: id, by, parent, story_id, text, time, type, kids, deleted, dead, _kafka_offset, _kafka_partition, _bronze_ingested_at

### Silver Layer (Cleaned)
**Stories**: id, author, title, url, score, comment_count, timestamp, text_raw, text_clean, has_url, has_text, type

**Comments**: id, author, story_id, parent, timestamp, text_raw, text_clean, has_text, word_count, char_count, has_replies, is_deleted, is_dead, quality_score, type

